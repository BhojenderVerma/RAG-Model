# RAG PDF QA with Ollama & Streamlit

This project is a Retrieval-Augmented Generation (RAG) app that lets you ask questions about your PDF documents using a local LLM (Ollama) and a simple web interface (Streamlit).

## Features

- Upload and process PDFs
- Ask questions in natural language
- Answers generated by a local LLM (e.g., Llama 3 via Ollama)
- Runs entirely on your computer (no cloud required)

## Setup

1. **Install Ollama**  
   [Download and install Ollama](https://ollama.com/download) and pull a model, e.g.:llama3
   ollama pull llama3


3. **Install Python dependencies**
   pip install -r requirements.txt

4. **Add your PDFs**  
Place your PDF files in the `data/` folder.

5. **Run the app**
- Start Ollama in one terminal:
  ```
  ollama serve
  ```
- Start Streamlit in another terminal:
  ```
  streamlit run app.py
  ```

5. **(Optional) Share with others**  
Use [ngrok](https://ngrok.com/) to make your app accessible over the internet: ngrok http 8501



## Demo
![query](https://github.com/user-attachments/assets/45651eff-101d-4bd0-9cf8-f66f85d62beb)
![response-1](https://github.com/user-attachments/assets/3b2efb47-2cc0-4354-be9e-75509cd3417a)
![response-2](https://github.com/user-attachments/assets/90972537-59ca-4c61-98a4-1358637ea3db)





## License

MIT License (or your preferred license)

