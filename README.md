# RAG PDF QA with Ollama & Streamlit

This project is a Retrieval-Augmented Generation (RAG) app that lets you ask questions about your PDF documents using a local LLM (Ollama) and a simple web interface (Streamlit).

## Features

- Upload and process PDFs
- Ask questions in natural language
- Answers generated by a local LLM (e.g., Llama 3 via Ollama)
- Runs entirely on your computer (no cloud required)

## Setup

1. **Install Ollama**  
   [Download and install Ollama](https://ollama.com/download) and pull a model, e.g.:llama3


2. **Install Python dependencies**

3. **Add your PDFs**  
Place your PDF files in the `data/` folder.

4. **Run the app**
- Start Ollama in one terminal:
  ```
  ollama serve
  ```
- Start Streamlit in another terminal:
  ```
  streamlit run app.py
  ```

5. **(Optional) Share with others**  
Use [ngrok](https://ngrok.com/) to make your app accessible over the internet:



## Demo
![query](https://github.com/user-attachments/assets/51f767f8-85a1-40ab-9810-eb61fc7b76f1)
![response-1](https://github.com/user-attachments/assets/b5fab80d-33cc-4cae-bae5-9f2f6efeffe9)
![response-2](https://github.com/user-attachments/assets/211e076e-d116-424e-bb7f-746dd65ba18b)





## License

MIT License (or your preferred license)

